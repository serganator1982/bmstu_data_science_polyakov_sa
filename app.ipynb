{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300c53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем необходимые библиотеки\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6998777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите параметры:\n"
     ]
    }
   ],
   "source": [
    "#os.system('cls||clear') - очистка окна консоли\n",
    "os.system('cls||clear')\n",
    "print('Введите путь до файла с данными для обучения модели:') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f80d2861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yp/Documents/all.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Вводим путь до файла с данными вместе с названием и расширением (датасет)\n",
    "file_parh = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d2669a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем датасет\n",
    "data = pd.read_excel(file_parh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Информационное сообщение о прогрессе\n",
    "os.system('cls||clear')\n",
    "print('Идет предобработка данных (исключение выбросов)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7aec808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#После загрузки данных проводим исключение выбросов в автоматическом режиме (трижды)\n",
    "#По всем столбцам, для которых есть выбросы, сделаем замену выбросов на пустые значения\n",
    "k = 0\n",
    "while k < 3:\n",
    "    i = 0\n",
    "    while i < len(data.columns):\n",
    "        x = data.columns[i]\n",
    "        q75,q25 = np.percentile(data.loc[:,x],[75,25])\n",
    "        intr_qr = q75-q25\n",
    "        max = q75+(1.5*intr_qr)\n",
    "        min = q25-(1.5*intr_qr)\n",
    "        data.loc[data[x]<min,x] = np.nan\n",
    "        data.loc[data[x]>max,x] = np.nan\n",
    "        i += 1\n",
    "    #Исключим те строки, которые содержат выбросы (пустые значения по некоторым столбцам)\n",
    "    data = data.dropna(axis=0)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abfcd005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JИдет нормализация данных\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: cls: command not found\n"
     ]
    }
   ],
   "source": [
    "#Информационное сообщение о прогрессе\n",
    "os.system('cls||clear')\n",
    "print('Идет нормализация данных')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6759ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем данные (приведем к диапазону [0,1])\n",
    "from sklearn import preprocessing\n",
    "minmaxscalar = preprocessing.MinMaxScaler()\n",
    "col = data.columns\n",
    "result = minmaxscalar.fit_transform(data)\n",
    "minmaxresult = pd.DataFrame(result, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff92b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Информационное сообщение о прогрессе\n",
    "os.system('cls||clear')\n",
    "print('Идет настройка библиотек')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем библиотеки для построения моделей\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Импорт TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdf2bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Список моделей для пронозирования\n",
    "models = [\"LinearRegression\", \"KNeighborsRegressor\", \"GradientBoostingRegressor\", \"NeuralNetwork\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edd3a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объявляем функцию для обучения модели линейной регрессии. На входе в функцию обучающая выборка, на выходе модель\n",
    "def LRmodel(test_features, test_labels):\n",
    "    #Подставляем оптимальные гиперпараметры в модель\n",
    "    model_base = LinearRegression(positive=True)\n",
    "    #Обучаем модель\n",
    "    model_base.fit(test_features,test_labels)\n",
    "    return model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "698b2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объявляем функцию для обучения модели ближайших соседей. На входе в функцию обучающая выборка, на выходе модель\n",
    "def KNRmodel(test_features, test_labels):\n",
    "    #Подставляем оптимальные гиперпараметры в модель\n",
    "    model_base = KNeighborsRegressor(algorithm='brute', leaf_size=10, n_neighbors=100, weights='distance')\n",
    "    #Обучаем модель\n",
    "    model_base.fit(test_features,test_labels)\n",
    "    return model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "667d7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объявляем функцию для обучения модели градиентного бустинга. На входе в функцию обучающая выборка, на выходе модель\n",
    "def GBRmodel(test_features, test_labels):\n",
    "    #Подставляем оптимальные гиперпараметры в модель\n",
    "    model_base = GradientBoostingRegressor(loss='lad', max_depth=2)\n",
    "    #Обучаем модель\n",
    "    model_base.fit(test_features,np.ravel(test_labels))\n",
    "    return model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cc357f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объявляем функцию для обучения нейросети. На входе в функцию обучающая выборка, тестовая выборка, список входных параметров\n",
    "#список выходных параметров, датасет, на выходе сама нейросеть. Но в самой функции происходит также проверка сети на тестовых данных\n",
    "#Ввод параметров для оценки целевой переменной и вывод прогнозного значения\n",
    "def NNmodel(test_features, test_labels, Xtest1, Ytest1, colni, colno, data_v):\n",
    "    #Переформатируем данные в массив\n",
    "    trgn_data = test_labels.values\n",
    "    trnn_data = test_features.values\n",
    "    trgn_data = np.ravel(trgn_data)\n",
    "    Xtrnn = trnn_data \n",
    "    Ytrnn = trgn_data\n",
    "    #Объявляем плейсхолдеры\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, 10])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "    #Инициализаторы\n",
    "    sigma = 1\n",
    "    weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "    bias_initializer = tf.zeros_initializer()\n",
    "    #Параметры архитектуры модели\n",
    "    n_start = 10\n",
    "    n_neurons_1 = 32\n",
    "    n_neurons_2 = 16\n",
    "    n_neurons_3 = 8\n",
    "    n_neurons_4 = 4\n",
    "    n_target = 1\n",
    "    #Уровень 1: Переменные для скрытых весов и смещений\n",
    "    W_hidden_1 = tf.Variable(weight_initializer([n_start, n_neurons_1]))\n",
    "    bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "    #Уровень 2: Переменные для скрытых весов и смещений\n",
    "    W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "    bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "    #Уровень 3: Переменные для скрытых весов и смещений\n",
    "    W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "    bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "    #Уровень 4: Переменные для скрытых весов и смещений\n",
    "    W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "    bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "    #Уровень выходных данных: Переменные для скрытых весов и смещений\n",
    "    W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))\n",
    "    bias_out = tf.Variable(bias_initializer([n_target]))\n",
    "    #Скрытый уровень\n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "    hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "    hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "    #Выходной уровень (должен быть транспонирован)\n",
    "    out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "    #Функция стоимости\n",
    "    mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "    #Оптимизатор\n",
    "    opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "    #Создание сессии\n",
    "    netn2 = tf.Session()\n",
    "    #Запуск инициализатора\n",
    "    netn2.run(tf.global_variables_initializer())\n",
    "\n",
    "    #Количество эпох и размер куска данных\n",
    "    epochs = 100\n",
    "    batch_size = 50\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        #Перемешивание данных для обучения\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(Ytrnn)))\n",
    "        Xtrnn = Xtrnn[shuffle_indices]\n",
    "        Ytrnn = Ytrnn[shuffle_indices]\n",
    "\n",
    "        #Обучение мини-партией\n",
    "        for i in range(0, len(Ytrnn) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = Xtrnn[start:start + batch_size]\n",
    "            batch_y = Ytrnn[start:start + batch_size]\n",
    "            netn2.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "    #Оцениваем точность на тестовом наборе\n",
    "    pred1 = netn2.run(out, feed_dict={X: Xtest1})\n",
    "    predict = np.reshape(pred1,(pred1.size, 1))\n",
    "    errors = abs(predict - Ytest1)\n",
    "    print('Средняя абсолютная ошибка оценки параметра', end =\" \")\n",
    "    print(np.mean(errors))\n",
    "    #Вводим и нормализуем данные, по которым будет осуществляться прогноз\n",
    "    imp_values = InputValues(colni, data_v)\n",
    "    #Осуществляем прогноз\n",
    "    predict_label = netn2.run(out, feed_dict={X: imp_values})\n",
    "    #Преобразуем из нормализованных данных в стандартные\n",
    "    col = colno\n",
    "    #Определим параметры, которые использовались для нормализации\n",
    "    minv = np.min(data_v[col])\n",
    "    maxv = np.max(data_v[col])\n",
    "    predict_label[0] = predict_label[0]*(maxv - minv) + minv\n",
    "    print(f\"Прогнозное значение параметра {col[0]} составляет {predict_label[0][0]}\")\n",
    "    return netn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d6567ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем функцию для вычисления точности модели. На входе модель, а также входные параметры и целевая переменная\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    #Делаем предсказание на основе входных параметров\n",
    "    predictions = model.predict(test_features)\n",
    "    #Считаем абсолютные ошибки в предсказаниях (разность между предсказанным значением и целевым значением)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    #Определяем точность модели\n",
    "    accuracy = 100 - mape\n",
    "    print('Средняя абсолютная ошибка: {:0.4f}'.format(np.mean(errors.values)))\n",
    "    #print('Точность = {:0.2f}%.'.format(accuracy[0]))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34cf89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем функцию для вычисления точности модели. На входе модель, а также входные параметры и целевая переменная\n",
    "def evaluate_2(model, test_features, test_labels):\n",
    "    #Делаем предсказание на основе входных параметров\n",
    "    predictions = model.predict(test_features)\n",
    "    #Преобразуем к виду [[],[],...] из одномерного массива\n",
    "    predict = np.reshape(predictions,(predictions.size, 1))\n",
    "    #Считаем абсолютные ошибки в предсказаниях (разность между предсказанным значением и целевым значением)\n",
    "    errors = abs(predict - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    #Определяем точность модели\n",
    "    accuracy = 100 - mape\n",
    "    print('Средняя абсолютная ошибка: {:0.4f}'.format(np.mean(errors.values)))\n",
    "    #print('Точность = {:0.2f}%.'.format(accuracy[0]))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f05dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем функцию, которая будет использоваться для заведения входных параметров. На входе список параметров,  датасет\n",
    "#На выходе получаем датафрейм с введенными параметрами\n",
    "def InputValues(cols, maindata):\n",
    "    #Создаем датафрем для входных значений\n",
    "    input_val = pd.DataFrame()\n",
    "    i = 0\n",
    "    while i < len(cols):\n",
    "        a = []\n",
    "        line = f\"Введите значение параметра ({cols[i]}): \"\n",
    "        param_val = input(line)\n",
    "        param_value = float(param_val)\n",
    "        #Проводим нормализацию данных на начальных (входных) данных модели\n",
    "        minv = np.min(maindata[cols[i]])\n",
    "        maxv = np.max(maindata[cols[i]])\n",
    "        param_value = (param_value - minv)/(maxv - minv)\n",
    "        a.append(param_value)\n",
    "        input_val[cols[i]] = a\n",
    "        i += 1\n",
    "    return input_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb11ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exitway = 'Y' #Переменная для выхода из приложения\n",
    "while exitway != 'N':\n",
    "    os.system('cls||clear')\n",
    "    print('Выберите целевую переменную для прогнозирования из предложенного списка:')\n",
    "    colnames_in = []\n",
    "    #выводим список доступных параметров\n",
    "    i = 0\n",
    "    while i < len(data.columns):\n",
    "        print(data.columns[i])\n",
    "        colnames_in.append(data.columns[i])\n",
    "        i += 1\n",
    "    label = input() #вводим значение\n",
    "    colnames_out = []\n",
    "    colnames_out.append(label)\n",
    "    colnames_in.remove(label) #исключаем выбранный параметр из общего списка\n",
    "    param = 'Y' #переменная для выхода для цикла ниже\n",
    "    #цикл для исключения параметров из списка входных\n",
    "    while param != 'N':\n",
    "        os.system('cls||clear')\n",
    "        print('Выберите переменную для исключения из списка параметров, либо введите N для завершения исключения параметров:')\n",
    "        #выводим список доступных параметров\n",
    "        k = 0\n",
    "        while k < len(colnames_in):\n",
    "            print(colnames_in[k])\n",
    "            k += 1\n",
    "        param = input()\n",
    "        if param != 'N':\n",
    "            colnames_in.remove(param)  #исключаем выбранный параметр из общего списка  \n",
    "    k = 0\n",
    "    #Разделим параметры\n",
    "    #Выходные\n",
    "    trg = minmaxresult[colnames_out]\n",
    "    #Входные\n",
    "    trn = minmaxresult[colnames_in]\n",
    "    #Подготовка обучающей и тестовой выборок (соотношение 70 на 30)\n",
    "    Xtrn, Xtest, Ytrn, Ytest = train_test_split(trn, trg, test_size=0.3)\n",
    "    os.system('cls||clear')\n",
    "    print('Для продолжения нажмите любую клавишу, для переподбора параметров нажмите Y')\n",
    "    exitway = input()\n",
    "    if exitway != 'Y':\n",
    "        os.system('cls||clear')\n",
    "        print('Выберите прогнозную модель из списка:')\n",
    "        #выводим список прогнозных моделей\n",
    "        k = 0\n",
    "        while k < len(models):\n",
    "            print(models[k])\n",
    "            k += 1\n",
    "        model_name = input()\n",
    "        #информационное сообщение\n",
    "        print('Идет обучение модели')\n",
    "        if model_name == 'LinearRegression':\n",
    "            model = LRmodel(Xtrn, Ytrn)\n",
    "            os.system('cls||clear')\n",
    "            #Оцениваем точность на тестовом наборе\n",
    "            base_accuracy = evaluate(model, Xtest, Ytest)\n",
    "            #Цикл для многократного введения параметров и оценки выходной переменной\n",
    "            endparam = 'Y'\n",
    "            while endparam != 'END':\n",
    "                #Вводим и нормализуем данные, по которым будет осуществляться прогноз\n",
    "                imp_values = InputValues(colnames_in, data)\n",
    "                #Осуществляем прогноз\n",
    "                predict_label = model.predict(imp_values)\n",
    "                #Преобразуем из нормализованных данных в стандартные\n",
    "                col = colnames_out\n",
    "                #Определим параметры, которые использовались для нормализации\n",
    "                minv = np.min(data[col])\n",
    "                maxv = np.max(data[col])\n",
    "                #преобразуем к изначальному виду\n",
    "                predict_label[0] = predict_label[0]*(maxv - minv) + minv\n",
    "                print(f\"Прогнозное значение параметра {col[0]} составляет {predict_label[0][0]}\")\n",
    "                print(\"Для продолжения нажмите любую кнопку, для завершения введите END\")\n",
    "                endparam = input()\n",
    "        elif model_name == 'KNeighborsRegressor':\n",
    "            model = KNRmodel(Xtrn, Ytrn)\n",
    "            os.system('cls||clear')\n",
    "            #Оцениваем точность на тестовом наборе\n",
    "            base_accuracy = evaluate(model, Xtest, Ytest)\n",
    "            #Цикл для многократного введения параметров и оценки выходной переменной\n",
    "            endparam = 'Y'\n",
    "            while endparam != 'END':\n",
    "                #Вводим и нормализуем данные, по которым будет осуществляться прогноз\n",
    "                imp_values = InputValues(colnames_in, data)\n",
    "                #Осуществляем прогноз\n",
    "                predict_label = model.predict(imp_values)\n",
    "                #Преобразуем из нормализованных данных в стандартные\n",
    "                col = colnames_out\n",
    "                #Определим параметры, которые использовались для нормализации\n",
    "                minv = np.min(data[col])\n",
    "                maxv = np.max(data[col])\n",
    "                #преобразуем к изначальному виду\n",
    "                predict_label[0] = predict_label[0]*(maxv - minv) + minv\n",
    "                print(f\"Прогнозное значение параметра {col[0]} составляет {predict_label[0][0]}\")\n",
    "                print(\"Для продолжения нажмите любую кнопку, для завершения введите END\")\n",
    "                endparam = input()\n",
    "        elif model_name == 'GradientBoostingRegressor':\n",
    "            model = GBRmodel(Xtrn, Ytrn)\n",
    "            os.system('cls||clear')\n",
    "            #Оцениваем точность на тестовом наборе\n",
    "            base_accuracy = evaluate_2(model, Xtest, Ytest)\n",
    "            #Цикл для многократного введения параметров и оценки выходной переменной\n",
    "            endparam = 'Y'\n",
    "            while endparam != 'END':\n",
    "                #Вводим и нормализуем данные, по которым будет осуществляться прогноз\n",
    "                imp_values = InputValues(colnames_in, data)\n",
    "                #Осуществляем прогноз\n",
    "                predict_label = model.predict(imp_values)\n",
    "                #Преобразуем из нормализованных данных в стандартные\n",
    "                col = colnames_out\n",
    "                #Определим параметры, которые использовались для нормализации\n",
    "                minv = np.min(data[col])\n",
    "                maxv = np.max(data[col])\n",
    "                #преобразуем к изначальному виду\n",
    "                predict_label[0] = predict_label[0]*(maxv - minv) + minv\n",
    "                print(f\"Прогнозное значение параметра {col[0]} составляет {predict_label[0]}\")\n",
    "                print(\"Для продолжения нажмите любую кнопку, для завершения введите END\")\n",
    "                endparam = input()\n",
    "        elif model_name == 'NeuralNetwork':\n",
    "            os.system('cls||clear')\n",
    "            model = NNmodel(Xtrn, Ytrn, Xtest, Ytest, colnames_in, colnames_out, data)\n",
    "        else:\n",
    "            os.system('cls||clear')\n",
    "            print('Ошибка при выборе модели, вернитесь к подбору параметров')\n",
    "        print('Для возвращения к выбору параметров нажмите любую клавишу. Для завершения введите N')\n",
    "        exitway = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804845e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
